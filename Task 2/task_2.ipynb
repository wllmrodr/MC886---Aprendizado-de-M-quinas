{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6d487d4a-eb77-49fa-b6c9-20a7713b4076",
      "metadata": {
        "id": "6d487d4a-eb77-49fa-b6c9-20a7713b4076",
        "tags": []
      },
      "source": [
        "# Group information\n",
        "\n",
        "Names: William Rodrigues Lopes, \n",
        "\n",
        "\n",
        "RAs:248499, "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c15d405f-6ecb-4b9c-b788-4f7f8ba12b09",
      "metadata": {
        "id": "c15d405f-6ecb-4b9c-b788-4f7f8ba12b09",
        "tags": []
      },
      "source": [
        "# **Machine Learning MC886/MO444 - Task \\#2**: Model Selection for classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "648e846a-c820-4e99-a868-2678b00e36c1",
      "metadata": {
        "id": "648e846a-c820-4e99-a868-2678b00e36c1",
        "tags": []
      },
      "source": [
        "### Objective:\n",
        "\n",
        "To explore **Model Selection** techniques to select the best model and hyperparameters for a classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d32be33a-2107-4380-80ff-0bae77bb0d96",
      "metadata": {
        "id": "d32be33a-2107-4380-80ff-0bae77bb0d96",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "## Airline Passenger Satisfaction\n",
        "\n",
        "**Context**\n",
        "\n",
        "This dataset contains an airline passenger satisfaction survey. What factors are highly correlated to a satisfied (or dissatisfied) passenger? Can you predict passenger satisfaction?\n",
        "\n",
        "**Content**\n",
        "\n",
        "| Column | Description |\n",
        "|---|---|\n",
        "| Gender | Gender of the passengers (Female, Male) |\n",
        "| Customer Type | The customer type (Loyal customer, disloyal customer) |\n",
        "| Age | The actual age of the passengers |\n",
        "| Type of Travel | Purpose of the flight of the passengers (Personal Travel, Business Travel) |\n",
        "| Class | Travel class in the plane of the passengers (Business, Eco, Eco Plus) |\n",
        "| Flight Distance | The flight distance of this journey |\n",
        "| Inflight wifi service | Satisfaction level of the inflight wifi service (0:Not Applicable;1-5) |\n",
        "| Departure/Arrival time convenient | Satisfaction level of Departure/Arrival time convenient |\n",
        "| Ease of Online booking | Satisfaction level of online booking |\n",
        "| Gate location | Satisfaction level of Gate location |\n",
        "| Food and drink | Satisfaction level of Food and drink |\n",
        "| Online boarding | Satisfaction level of online boarding |\n",
        "| Seat comfort | Satisfaction level of Seat comfort |\n",
        "| Inflight entertainment | Satisfaction level of inflight entertainment |\n",
        "| On-board service | Satisfaction level of On-board service |\n",
        "| Leg room service | Satisfaction level of Leg room service |\n",
        "| Baggage handling | Satisfaction level of baggage handling |\n",
        "| Check-in service | Satisfaction level of Check-in service |\n",
        "| Inflight service | Satisfaction level of inflight service |\n",
        "| Cleanliness | Satisfaction level of Cleanliness |\n",
        "| Departure Delay in Minutes | Minutes delayed when departure |\n",
        "| Arrival Delay in Minutes | Minutes delayed when Arrival |\n",
        "| Satisfaction | Airline satisfaction level(Satisfaction, neutral or dissatisfaction) |\n",
        "\n",
        "**Note:** This data set was modified from this dataset by John D here. It has been cleaned up for the purposes of classification."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f72b830c-1077-41c6-aad5-e2943ba29da4",
      "metadata": {
        "id": "f72b830c-1077-41c6-aad5-e2943ba29da4"
      },
      "source": [
        "**How to load the dataset**\n",
        "\n",
        "Dataset link: [here](https://drive.google.com/drive/folders/1Wagh0CUKWzjssOif6n4b9dpkzq50bamx?usp=sharing)\n",
        "\n",
        "You should open the google drive folder, click on the name of the folder on the top and click on \"organize\" => \"add shortcut\".<br/>\n",
        "Then you should choose where to add the shortcut. The recommendation is to add on \"MyDrive\", so you don't need to change the dataset path used below.\n",
        "\n",
        "Then you should run the cell below and authorize google drive access.\n",
        "\n",
        "*If you want to run the notebook locally, just download the folder and change the path below to the location of the folder in your local environment.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18ad021-6d11-4c10-bde1-d920bbade527",
      "metadata": {
        "id": "a18ad021-6d11-4c10-bde1-d920bbade527"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/treino.csv'\n",
        "\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02770f4d-3425-458c-8de0-0968b5ac89c8",
      "metadata": {
        "id": "02770f4d-3425-458c-8de0-0968b5ac89c8",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### **Data analysis and preprocessing** (1.5 points)\n",
        "\n",
        "In this section, you should explore the dataset. Remember to avoid using data that you should not have in training.\n",
        "\n",
        "You can plot graphs with features that you think are important to visualize the relation with the target(`Satisfaction`). You can also use boxplot graphs to understand feature distributions. There are no minimal/maximum requirements in what graphs you should use, explore just what you think can help in understanding the dataset.\n",
        "\n",
        "As in the previous task, preprocess the data, transform the categorical features with OneHotEncoding, and remember to scale continuous features to be in a similar scale between each other.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5d4634-6ae8-4cd2-8aea-7f4d2f29ecaa",
      "metadata": {
        "id": "9b5d4634-6ae8-4cd2-8aea-7f4d2f29ecaa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# raciocínio idêntico ao da task 1, com os gráficos fica mais nítida a relação de Satisfaction com outras variáveis.\n",
        "\n",
        "data['satisfaction_numeric'] = data['satisfaction'].apply(lambda x: 1 if x == 'satisfied' else 0)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "# primeiro gráfico: Satisfaction vs Flight Distance\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.boxplot(x='satisfaction_numeric', y='Flight Distance', data=data)\n",
        "plt.title('Satisfaction vs Flight Distance')\n",
        "plt.xlabel('Satisfaction')\n",
        "plt.ylabel('Flight Distance')\n",
        "\n",
        "# segundo gráfico: Satisfaction vs Inflight wifi service\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.boxplot(x='satisfaction_numeric', y='Inflight wifi service', data=data)\n",
        "plt.title('Satisfaction vs Inflight Wifi Service')\n",
        "plt.xlabel('Satisfaction')\n",
        "plt.ylabel('Inflight Wifi Service Rating')\n",
        "\n",
        "# terceiro gráfico: Satisfaction vs Class\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.countplot(x='Class', hue='satisfaction_numeric', data=data)\n",
        "plt.title('Satisfaction vs Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# quarto gráfico: Satisfaction vs Departure Delay in Minutes\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.boxplot(x='satisfaction_numeric', y='Departure Delay in Minutes', data=data)\n",
        "plt.title('Satisfaction vs Departure Delay')\n",
        "plt.xlabel('Satisfaction')\n",
        "plt.ylabel('Departure Delay (minutes)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e9969ce-ab47-4933-87a5-c6815e8eb121",
      "metadata": {
        "id": "1e9969ce-ab47-4933-87a5-c6815e8eb121",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### **Metric selection** (0.5 point)\n",
        "\n",
        "As we're working with unbalanced data, the accuracy metric is not a good indicator of performance. Choose a metric and explain why that metric is a good fit for the online shopping intention problem. You don't need to implement the metric, only discuss it.\n",
        "\n",
        "*Tip: Some common metrics are [balanced accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html), [recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html), [precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html), [f1-score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) and [AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc91ebe-fba0-4224-8fa5-992b8a9601e7",
      "metadata": {
        "id": "2cc91ebe-fba0-4224-8fa5-992b8a9601e7"
      },
      "outputs": [],
      "source": [
        "Para lidar com dados desbalanceados, a accuracy (precisão) não é uma boa métrica, porque ela pode levar a uma conclusão errada. Em um cenário onde a classe majoritária predomina, um modelo pode obter uma alta precisão simplesmente prevendo essa classe dominante o tempo todo, ignorando as instâncias da classe minoritária.\n",
        "\n",
        "Uma métrica mais adequada para o problema de satisfação de passageiros seria a F1-score, especialmente porque ela equilibra a precisão e o recall. O F1-score é a média harmônica entre a precisão e o recall. Ele é ideal para problemas desbalanceados, pois lida bem com cenários onde os falsos negativos (casos onde o modelo não identifica a classe minoritária corretamente) são importantes.\n",
        "\n",
        "Precisão no contextp: Quantos dos passageiros que o modelo classificou como \"satisfeitos\" estavam realmente satisfeitos.\n",
        "Recall no contexto: Quantos dos passageiros realmente satisfeitos foram identificados corretamente pelo modelo.\n",
        "\n",
        "O F1-score considera tanto os erros falsos positivos quanto os falsos negativos, equilibrando os dois lados do problema. Isso é importante para evitar que o modelo foque apenas na classe majoritária.Dessa forma, o F1-score oferece uma visão mais equilibrada sobre o desempenho do modelo em contextos onde os dados são desbalanceados."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a17e1b6-abee-488b-b171-77ff68e18ff9",
      "metadata": {
        "id": "7a17e1b6-abee-488b-b171-77ff68e18ff9",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### **Feature selection** (2 points)\n",
        "\n",
        "As seen in class, there are different ways to select which features to use in a machine learning model.\n",
        "\n",
        "You should implement the \"Forward stepwise selection\" technique to find the best `p` features to be used in this task according to that method.\n",
        "\n",
        "Use the [Logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model and the **K-fold cross-validation** as optimality criterion. You can use the Scikit-learn library, which has helper functions to create the [K-fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) logic and the model. The metric used in K-fold should be the one chosen in the previous section!\n",
        "\n",
        "Remember to save a new dataframe only with the selected features for the next steps! Also, use only training data on K-fold validation, keeping a test set separated to estimate the performance of the model on unseen data on the final part of the whole task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5811eef9-ef1c-4076-b739-77d68e3db465",
      "metadata": {
        "id": "5811eef9-ef1c-4076-b739-77d68e3db465"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#breve explicação do raciocínio por trás do código: \n",
        "# primeiro devemos tratar os valores faltantes\n",
        "# assim que tivermos as lacunas removidas, é necessário padronizar os dados (normalizar)\n",
        "# depois disso, verificamos as features constantes\n",
        "# por fim, padronizamos o erro em relação a f1\n",
        "\n",
        "\n",
        "# separa a variável alvo (satisfaction_numeric) das features\n",
        "X = data.drop(columns=['satisfaction', 'satisfaction_numeric', 'Unnamed: 0', 'id'])  # Remover colunas irrelevantes\n",
        "y = data['satisfaction_numeric']\n",
        "\n",
        "# converte as colunas categóricas em numéricas com One-Hot Encoding\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# verifica valores nulos\n",
        "if X_encoded.isnull().sum().sum() > 0:\n",
        "    # atribui valores faltantes (média ou mediana)\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_encoded = pd.DataFrame(imputer.fit_transform(X_encoded), columns=X_encoded.columns)\n",
        "\n",
        "# normaliza as features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X_encoded), columns=X_encoded.columns)\n",
        "\n",
        "# divide o dataset em treino (80%) e teste (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# define o modelo de regressão logística\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# define K-fold cross-validation com 5 folds\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# função de seleção Forward Stepwise\n",
        "def forward_stepwise_selection(X_train, y_train, model, kfold, max_features=5):\n",
        "    selected_features = []\n",
        "    remaining_features = list(X_train.columns)\n",
        "    best_f1 = 0\n",
        "    scorer = make_scorer(f1_score)\n",
        "\n",
        "    while len(selected_features) < max_features:\n",
        "        f1_scores = []\n",
        "        for feature in remaining_features:\n",
        "            # cria um conjunto de features temporário com a feature atual \n",
        "            features_to_evaluate = selected_features + [feature]\n",
        "            X_subset = X_train[features_to_evaluate]\n",
        "\n",
        "            try:\n",
        "                # calcula o F1-score médio usando cross-validation com erro\n",
        "                scores = cross_val_score(model, X_subset, y_train, cv=kfold, scoring=scorer, error_score='raise')\n",
        "                mean_f1 = np.mean(scores)\n",
        "                f1_scores.append((mean_f1, feature))\n",
        "            except Exception as e:\n",
        "                print(f\"Erro com a feature {feature}: {e}\")\n",
        "        \n",
        "        # seleciona a feature com o melhor F1-score médio\n",
        "        if f1_scores:\n",
        "            f1_scores.sort(reverse=True, key=lambda x: x[0])\n",
        "            best_new_f1, best_feature = f1_scores[0]\n",
        "            \n",
        "            if best_new_f1 > best_f1:\n",
        "                selected_features.append(best_feature)\n",
        "                remaining_features.remove(best_feature)\n",
        "                best_f1 = best_new_f1\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    return selected_features\n",
        "\n",
        "# seleciona as melhores features\n",
        "selected_features = forward_stepwise_selection(X_train, y_train, log_reg, kf, max_features=5)\n",
        "print(\"features selecionadas:\", selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3063991-d5d7-434b-a879-0e1d98d260b5",
      "metadata": {
        "id": "e3063991-d5d7-434b-a879-0e1d98d260b5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "07dce3da-0ecc-4a6f-a096-ef4cf38138d9",
      "metadata": {
        "id": "07dce3da-0ecc-4a6f-a096-ef4cf38138d9",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### **Model selection** (4 points)\n",
        "\n",
        "This is the main section of the task. Using the features selected in the previous section, you must use [**Grid search** with K-fold cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to select the best classification model and its hyperparameters for this task.\n",
        "\n",
        "Remember to use only training data on K-fold validation, keeping a test set separated to estimate the performance of the model on unseen data.\n",
        "\n",
        "You should train and validate the following models:\n",
        "- [Logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "- [Decision Trees](https://scikit-learn.org/stable/modules/tree.html), explore a Decision Tree Classifier, RF and GBM.\n",
        "- [SVM](https://scikit-learn.org/stable/modules/svm.html)\n",
        "\n",
        "Explore the documentation above and select which hyperparameters to vary.\n",
        "\n",
        "\n",
        "Also, you should test the polynomial transformation to find possible nonlinear relations between the features of the dataset. **Do not** use values above \"3\" for the `degree` of the polynomial transformation, as the number of features increases exponentially.\n",
        "\n",
        "In short, you should use GridSearchCV (that uses K-fold internally) to get the best hyperparameters for each model, while also testing the polynomial transformation.\n",
        "\n",
        "*Note: you will need to use the `fit` method more than once to test the different dataset transformations. Choose wisely which hyperparameters to test, as the GridSearch will test all combinations and can take very a long time to finish.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ed19c1b-d82d-4528-858c-1508ddbf500b",
      "metadata": {
        "id": "5ed19c1b-d82d-4528-858c-1508ddbf500b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c1ec7f1-8536-41ae-8658-afcc0bb69754",
      "metadata": {
        "id": "8c1ec7f1-8536-41ae-8658-afcc0bb69754"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294cbb36-437c-4204-a7f7-e01bf616f312",
      "metadata": {
        "id": "294cbb36-437c-4204-a7f7-e01bf616f312"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a6effc30-51f3-4acd-a3a2-211bec8e6865",
      "metadata": {
        "id": "a6effc30-51f3-4acd-a3a2-211bec8e6865",
        "tags": []
      },
      "source": [
        "#### Discussion of key points\n",
        "\n",
        "- What was the best model according to cross validation?\n",
        "- The models that use regularization were able to outperform the Logistic Regression? Explain why.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c2e193a-9e60-4d91-86bb-096ae36ba6bb",
      "metadata": {
        "id": "2c2e193a-9e60-4d91-86bb-096ae36ba6bb",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Threshold testing (1 point)\n",
        "\n",
        "The three models trained in the previous session can return the probabilities of a sample being of the positive class.\n",
        "The default threshold used to convert the results to the desired 0 or 1 output is `0.5`.\n",
        "\n",
        "Use the K-fold cross validation to test different thresholds with the best models trained in the previous section (remember to train the best models with all train data and the best hyperparameters).\n",
        "\n",
        "*If the model does not output probabilities, look for the `predic_proba` method*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a74e39b7-ba63-4796-8806-9a332df8c761",
      "metadata": {
        "id": "a74e39b7-ba63-4796-8806-9a332df8c761"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed71002-3c8b-426f-b9c3-2112aff99d97",
      "metadata": {
        "id": "bed71002-3c8b-426f-b9c3-2112aff99d97"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "077049b4-f1de-4542-a7c2-864e7025274a",
      "metadata": {
        "id": "077049b4-f1de-4542-a7c2-864e7025274a",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Visualizing/interpreting weights (0.5 point)\n",
        "\n",
        "As we're dealing with models that apply regularization terms, it's relatively easy to verify those results on the coefficient weights of the trained models.\n",
        "\n",
        "Use the function below to visualize the weights of the final models.</br>\n",
        "Also, train the three models again using *all* original features, and use the function below to compare how the weight distribution behaves on each of the models*.\n",
        "\n",
        "\\* *If no features were removed in previous sections, just compare the three models*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8284c967-db80-404d-bc74-097199f120e2",
      "metadata": {
        "id": "8284c967-db80-404d-bc74-097199f120e2"
      },
      "outputs": [],
      "source": [
        "## You don't need to change this cell!\n",
        "import plotly.express as px\n",
        "\n",
        "def plot_weights(model, columns):\n",
        "  '''\n",
        "  Plot the weights of the model for each column in an interative graph.\n",
        "  \"model\" should be an sklearn model or follow the same interface, having the \"coef_\" attribute with the weights.\n",
        "\n",
        "  -----\n",
        "  Examples:\n",
        "  plot_weights(classifier, X.columns)\n",
        "  # for polynomial transformations\n",
        "  plot_weights(classifier, poly.get_feature_names_out(X.columns))\n",
        "\n",
        "  '''\n",
        "  if not hasattr(clf, 'coef_'):\n",
        "    print(\"Invalid model!\")\n",
        "    return\n",
        "\n",
        "  df_plot = pd.DataFrame(columns=['weight','columns'])\n",
        "  df_plot['columns']= columns\n",
        "\n",
        "  if len(columns) == len(clf.coef_):\n",
        "    df_plot['weight']=clf.coef_\n",
        "  else:\n",
        "    df_plot['weight']=clf.coef_[0]\n",
        "\n",
        "  fig = px.bar(df_plot, x='columns', y='weight', color='weight')\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac5e133c-a484-476f-9e60-8b7c63b9af5c",
      "metadata": {
        "id": "ac5e133c-a484-476f-9e60-8b7c63b9af5c"
      },
      "outputs": [],
      "source": [
        "# Plot the weights of your models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7b6eeb-6677-4dfd-94e5-075e0c0302b1",
      "metadata": {
        "id": "8f7b6eeb-6677-4dfd-94e5-075e0c0302b1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "84d2b22f",
      "metadata": {},
      "source": [
        "### Explainability Tools (+0.5 points)\n",
        "\n",
        "Use explainability tools, like [SHAP](https://shap.readthedocs.io/en/latest/), explain how it works and apply to DT or Kernel SVM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f9986c5-4ea1-45ea-9283-d82fe30a046b",
      "metadata": {
        "id": "7f9986c5-4ea1-45ea-9283-d82fe30a046b",
        "tags": []
      },
      "source": [
        "#### Discussion of key points\n",
        "\n",
        "- What conclusions can you have when looking at the different graphs?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bbeeccb-4f4d-43ef-93a9-a42cd8357ea3",
      "metadata": {
        "id": "0bbeeccb-4f4d-43ef-93a9-a42cd8357ea3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35115a3-ce76-464f-9c00-e419485af9f1",
      "metadata": {
        "id": "c35115a3-ce76-464f-9c00-e419485af9f1"
      },
      "outputs": [],
      "source": [
        "hasattr(obj, 'attribute')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d102f9af-2476-4cf5-8b45-f43df78ffd11",
      "metadata": {
        "id": "d102f9af-2476-4cf5-8b45-f43df78ffd11",
        "tags": []
      },
      "source": [
        "### Testing (0.5 point)\n",
        "\n",
        "Finally, choose your **Best** model in validation, test it and plot the normalized confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b443d3a-e0d8-43b0-8442-089d103a6e51",
      "metadata": {
        "id": "7b443d3a-e0d8-43b0-8442-089d103a6e51"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff9805b7-5c4d-4df5-b2ea-73388f32e7c9",
      "metadata": {
        "id": "ff9805b7-5c4d-4df5-b2ea-73388f32e7c9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7694d383-b755-45a7-9f95-53c0ee433970",
      "metadata": {
        "id": "7694d383-b755-45a7-9f95-53c0ee433970"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "37fb3bdd-0e21-422a-a161-17150241f989",
      "metadata": {
        "id": "37fb3bdd-0e21-422a-a161-17150241f989",
        "tags": []
      },
      "source": [
        "## Deadline\n",
        "\n",
        "Tuesday, October 22, 11:59 pm."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b478147-33c3-4491-8d9b-677de65af878",
      "metadata": {
        "id": "6b478147-33c3-4491-8d9b-677de65af878",
        "tags": []
      },
      "source": [
        "## Submission\n",
        "\n",
        "On Google Classroom, submit your Jupyter Notebook (in Portuguese or English) or Google Colaboratory link (remember to share it!).\n",
        "\n",
        "**This activity is NOT individual, it must be done in pairs (two-person group).**\n",
        "\n",
        "Only one individual should deliver the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
